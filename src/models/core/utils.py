"""
åˆ®å‰Šè¿‡ç¨‹çš„ä¸€èˆ¬å·¥å…·å‡½æ•°
ä¾èµ–:
    æ­¤æ¨¡å—ä¸åº”ä¾èµ– models.core ä¸­é™¤ flags å¤–çš„ä»»ä½•å…¶ä»–æ¨¡å—
"""

import os
import re
import traceback

import cv2
import unicodedata

from models.base.file import read_link, split_path
from models.base.number import get_number_letters
from models.base.path import get_main_path, get_path
from models.base.utils import convert_path, get_used_time
from models.config.config import config
from models.config.resources import resources
from models.signals import signal
from itertools import product
from collections import defaultdict

def replace_word(json_data):
    # å¸¸è§å­—æ®µæ›¿æ¢çš„å­—ç¬¦
    for key, value in config.all_rep_word.items():
        for each in config.all_key_word:
            json_data[each] = json_data[each].replace(key, value)

    # ç®€ä½“æ—¶æ›¿æ¢çš„å­—ç¬¦
    key_word = []
    if config.title_language == "zh_cn":
        key_word.append("title")
    if config.outline_language == "zh_cn":
        key_word.append("outline")

    for key, value in config.chinese_rep_word.items():
        for each in key_word:
            json_data[each] = json_data[each].replace(key, value)

    # æ›¿æ¢æ ‡é¢˜çš„ä¸Šä¸‹é›†ä¿¡æ¯
    fields_word = ["title", "originaltitle"]
    for field in fields_word:
        for each in config.title_rep:
            json_data[field] = json_data[field].replace(each, "").strip(":ï¼Œ ").strip()


def show_movie_info(json_data):
    if config.show_data_log == "off":  # è°ƒè¯•æ¨¡å¼æ‰“å¼€æ—¶æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        return
    for key in config.show_key:
        value = json_data.get(key)
        if not value:
            continue
        if key == "outline" or key == "originalplot" and len(value) > 100:
            value = str(value)[:98] + "â€¦â€¦ï¼ˆç•¥ï¼‰"
        elif key == "has_sub":
            value = "ä¸­æ–‡å­—å¹•"
        elif key == "actor" and "actor_all," in config.nfo_include_new:
            value = json_data["all_actor"]
        json_data["logs"] += "\n     " + "%-13s" % key + ": " + str(value)


def get_video_size(json_data, file_path):
    # è·å–æœ¬åœ°åˆ†è¾¨ç‡ åŒæ—¶è·å–è§†é¢‘ç¼–ç æ ¼å¼
    definition = ""
    height = 0
    hd_get = config.hd_get
    if os.path.islink(file_path):
        if "symlink_definition" in config.no_escape:
            file_path = read_link(file_path)
        else:
            hd_get = "path"
    if hd_get == "video":
        try:
            cap = cv2.VideoCapture(file_path)
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            ##ä½¿ç”¨opencvè·å–ç¼–ç å™¨æ ¼å¼
            codec = int(cap.get(cv2.CAP_PROP_FOURCC))
            codec_fourcc = (
                chr(codec & 0xFF) + chr((codec >> 8) & 0xFF) + chr((codec >> 16) & 0xFF) + chr((codec >> 24) & 0xFF)
            )

        except Exception as e:
            signal.show_traceback_log(traceback.format_exc())
            signal.show_traceback_log(str(e))
            signal.show_log_text(traceback.format_exc())
            signal.show_log_text(f" ğŸ”´ æ— æ³•è·å–è§†é¢‘åˆ†è¾¨ç‡ï¼ æ–‡ä»¶åœ°å€: {file_path}  é”™è¯¯ä¿¡æ¯: {e}")
    elif hd_get == "path":
        file_path_temp = file_path.upper()
        if "8K" in file_path_temp:
            height = 4000
        elif "4K" in file_path_temp or "UHD" in file_path_temp:
            height = 2000
        elif "1440P" in file_path_temp or "QHD" in file_path_temp:
            height = 1440
        elif "1080P" in file_path_temp or "FHD" in file_path_temp:
            height = 1080
        elif "960P" in file_path_temp:
            height = 960
        elif "720P" in file_path_temp or "HD" in file_path_temp:
            height = 720

    hd_name = config.hd_name
    if not height:
        pass
    elif height >= 4000:
        definition = "8K" if hd_name == "height" else "UHD8"
    elif height >= 2000:
        definition = "4K" if hd_name == "height" else "UHD"
    elif height >= 1400:
        definition = "1440P" if hd_name == "height" else "QHD"
    elif height >= 1000:
        definition = "1080P" if hd_name == "height" else "FHD"
    elif height >= 900:
        definition = "960P" if hd_name == "height" else "HD"
    elif height >= 700:
        definition = "720P" if hd_name == "height" else "HD"
    elif height >= 500:
        definition = "540P" if hd_name == "height" else "qHD"
    elif height >= 400:
        definition = "480P"
    elif height >= 300:
        definition = "360P"
    elif height >= 100:
        definition = "144P"
    json_data["definition"] = definition

    if definition in ["4K", "8K", "UHD", "UHD8"]:
        json_data["4K"] = "-" + definition

    # å»é™¤æ ‡ç­¾ä¸­çš„åˆ†è¾¨ç‡ç‡ï¼Œä½¿ç”¨æœ¬åœ°è¯»å–çš„å®é™…åˆ†è¾¨ç‡
    remove_key = ["144P", "360P", "480P", "540P", "720P", "960P", "1080P", "1440P", "2160P", "4K", "8K"]
    tag = json_data["tag"]
    for each_key in remove_key:
        tag = tag.replace(each_key, "").replace(each_key.lower(), "")
    tag_list = re.split(r"[,ï¼Œ]", tag)
    new_tag_list = []
    [new_tag_list.append(i) for i in tag_list if i]
    if definition and "definition" in config.tag_include:
        new_tag_list.insert(0, definition)
        if hd_get == "video":
            new_tag_list.insert(0, codec_fourcc.upper())  # æ’å…¥ç¼–ç æ ¼å¼
    json_data["tag"] = "ï¼Œ".join(new_tag_list)
    return json_data


def show_data_result(json_data, start_time):
    if json_data["error_info"] or json_data["title"] == "":
        json_data["logs"] += (
            "\n ğŸŒ [website] %s" % json_data["req_web"].strip("-> ")
            + "\n"
            + json_data["log_info"].strip(" ").strip("\n")
            + "\n"
            + " ğŸ”´ Data failed!(%ss)" % (get_used_time(start_time))
        )
        return False
    else:
        if config.show_web_log == "on":  # å­—æ®µåˆ®å‰Šè¿‡ç¨‹
            json_data["logs"] += "\n ğŸŒ [website] %s" % json_data["req_web"].strip("-> ")
        try:
            if json_data["log_info"]:
                json_data["logs"] += "\n" + json_data["log_info"].strip(" ").strip("\n")
        except:
            signal.show_log_text(traceback.format_exc())
        if config.show_from_log == "on":  # å­—æ®µæ¥æºä¿¡æ¯
            if json_data["fields_info"]:
                json_data["logs"] += "\n" + json_data["fields_info"].strip(" ").strip("\n")
        json_data["logs"] += "\n ğŸ€ Data done!(%ss)" % (get_used_time(start_time))
        return True


def deal_url(url):
    if "://" not in url:
        url = "https://" + url
    url = url.strip()
    for key, vlaue in config.web_dic.items():
        if key.lower() in url.lower():
            return vlaue, url

    # è‡ªå®šä¹‰çš„ç½‘å€
    for web_name in config.SUPPORTED_WEBSITES:
        if hasattr(config, web_name + "_website"):
            web_url = getattr(config, web_name + "_website")
            if web_url in url:
                return web_name, url

    return False, url


def replace_special_word(json_data):
    # å¸¸è§å­—æ®µæ›¿æ¢çš„å­—ç¬¦
    all_key_word = [
        "title",
        "originaltitle",
        "outline",
        "originalplot",
        "series",
        "director",
        "studio",
        "publisher",
        "tag",
    ]
    for key, value in config.special_word.items():
        for each in all_key_word:
            json_data[each] = json_data[each].replace(key, value[0])
    
def convert_half(string, operation_flags=0b111):
    """
    å¤šé˜¶æ®µæ–‡æœ¬å¤„ç†å‡½æ•°ï¼Œæ”¯æŒæ•æ„Ÿè¯æ›¿æ¢ã€å­—ç¬¦æ ¼å¼è½¬æ¢å’Œæ¸…ç†
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. æ•æ„Ÿè¯æ›¿æ¢ï¼šæ ¹æ®é…ç½®æ›¿æ¢åŒ…å«å±è”½ç¬¦å·(â—/â—‹)çš„è¯æ±‡ï¼Œæ”¯æŒåŒå‘æ˜ å°„
    2. å…¨è§’è½¬åŠè§’ï¼šè½¬æ¢é…ç½®æŒ‡å®šçš„å…¨è§’å­—ç¬¦ä¸ºåŠè§’
    3. æ ¼å¼æ¸…ç†ï¼šç§»é™¤éå•è¯å­—ç¬¦å¹¶è½¬ä¸ºå¤§å†™
    
    å‚æ•°ï¼š
    string (str): å¾…å¤„ç†çš„åŸå§‹å­—ç¬¦ä¸²
    operation_flags (int): ä½æ ‡å¿—æ§åˆ¶å¤„ç†æµç¨‹
        - 0b001 (1): æ‰§è¡Œæ•æ„Ÿè¯æ›¿æ¢
        - 0b010 (2): æ‰§è¡Œå…¨è§’è½¬åŠè§’
        - 0b100 (4): æ‰§è¡Œæ ¼å¼æ¸…ç†å’Œå¤§å†™è½¬æ¢
    
    è¿”å›ï¼š
    list: å¤„ç†åçš„å­—ç¬¦ä¸²åˆ—è¡¨ï¼ŒæŒ‰æœªå±è”½ç‰ˆæœ¬ä¼˜å…ˆæ’åºï¼Œä¿æŒå”¯ä¸€æ€§
    """
    
    def generate_normalized_mapping(special_word):
        """
        ç”Ÿæˆæ ‡å‡†åŒ–æ˜ å°„å­—å…¸ï¼Œç”¨äºå…¨å¤„ç†æ¨¡å¼ä¸‹çš„å­—ç¬¦æ›¿æ¢
        å¤„ç†è§„åˆ™ï¼šå°†åŒ…å«â—/â—‹çš„é”®æ˜ å°„åˆ°å»æ‰å¯¹åº”ä½ç½®å­—ç¬¦çš„å€¼
        ç¤ºä¾‹ï¼š"å¼·â—" => ("å¼·åˆ¶","å¼·å§¦") ä¼šç”Ÿæˆæ˜ å°„ï¼š"å¼·â—"->"å¼·", "å¼·åˆ¶"->"å¼·", "å¼·å§¦"->"å¼·"
        """
        normalized = defaultdict(set)
        for key, values in special_word.items():
            for v in values:
                # ä»…å¤„ç†åŒ…å«å±è”½ç¬¦å·çš„é”®
                if "â—" in key or "â—‹" in key:
                    # è®¡ç®—å±è”½ç¬¦å·ä½ç½®
                    symbol = "â—" if "â—" in key else "â—‹"
                    index = key.index(symbol)
                    # ç”Ÿæˆæ ‡å‡†åŒ–ç»“æœï¼ˆå»æ‰å¯¹åº”ä½ç½®å­—ç¬¦ï¼‰
                    normalized_target = v[:index] + v[index+1:] if index < len(v) else v
                    # å»ºç«‹åŒå‘æ˜ å°„
                    normalized[key].add(normalized_target)
                    normalized[v].add(normalized_target)
        return {k: list(v) for k, v in normalized.items()}

    # åˆå§‹åŒ–ç»“æœé›†åˆï¼Œä¿ç•™åŸå§‹å­—ç¬¦ä¸²
    results = {string}

    # ========================
    # é˜¶æ®µ1ï¼šæ•æ„Ÿè¯æ›¿æ¢å¤„ç†
    # ========================
    if operation_flags & 0b001:
        # æ„å»ºåå‘æ˜ å°„å­—å…¸ï¼ˆæ ‡å‡†è¯ -> æ‰€æœ‰å¯èƒ½çš„å±è”½å½¢å¼ï¼‰
        reverse_special_word = defaultdict(list)
        for key, values in config.special_word.items():
            targets = values if isinstance(values, (tuple, list)) else [values]
            for target in targets:
                reverse_special_word[target].append(key)

        # åˆå¹¶æ­£å‘å’Œåå‘æ˜ å°„ï¼Œæ„å»ºå®Œæ•´æ›¿æ¢å­—å…¸
        all_replacements = defaultdict(tuple)
        # æ·»åŠ æ­£å‘æ˜ å°„
        for key, values in config.special_word.items():
            targets = values if isinstance(values, (tuple, list)) else [values]
            all_replacements[key] = tuple(targets)
        # åˆå¹¶åå‘æ˜ å°„
        for key, sources in reverse_special_word.items():
            existing = list(all_replacements.get(key, ()))
            existing.extend(sources)
            all_replacements[key] = tuple(set(existing))  # å»é‡

        # æ ¹æ®å¤„ç†æ¨¡å¼é€‰æ‹©æ˜ å°„è¡¨
        replacements = (
            generate_normalized_mapping(all_replacements) 
            if (operation_flags & 0b100)  # å…¨å¤„ç†æ¨¡å¼éœ€è¦æ ‡å‡†åŒ–æ˜ å°„
            else {k: list(v) for k, v in all_replacements.items()}
        )

        # é¢„å¤„ç†ï¼šç»Ÿä¸€â—‹ä¸ºâ—ä»¥ä¾¿åŒ¹é…
        processed_str = string.replace("â—‹", "â—")
        # æŒ‰é•¿åº¦é™åºæ’åºæ¨¡å¼ï¼Œç¡®ä¿é•¿æ¨¡å¼ä¼˜å…ˆåŒ¹é…
        sorted_patterns = sorted(replacements.keys(), key=lambda x: (-len(x), x))
        pattern = re.compile("|".join(map(re.escape, sorted_patterns)))
        matches = pattern.finditer(processed_str)

        if matches:
            # å°†åŒ¹é…é¡¹æŒ‰åŸå§‹æ¨¡å¼åˆ†ç»„ï¼ˆç›¸åŒæ¨¡å¼çš„ä¸åŒåŒ¹é…å½’ä¸ºä¸€ç»„ï¼‰
            pattern_groups = defaultdict(list)
            for m in matches:
                matched_pattern = m.group()
                pattern_groups[matched_pattern].append(m)

            # åˆå§‹åŒ–æ›¿æ¢é€‰é¡¹å­—å…¸
            filter_special = (operation_flags == 0b111)  # å…¨å¤„ç†æ¨¡å¼éœ€è¦è¿‡æ»¤å±è”½ç¬¦å·
            replacement_options = {}
            patterns = list(pattern_groups.keys())  # è·å–å”¯ä¸€æ¨¡å¼åˆ—è¡¨

            # åˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ åŸè¯é€‰é¡¹ï¼ˆæ··åˆå­˜åœ¨å±è”½è¯å’Œæœªå±è”½è¯æ—¶æ‰éœ€è¦ï¼‰
            has_shielded = any(p in config.special_word for p in patterns)
            has_unshielded = any(p not in config.special_word for p in patterns)
            need_extra = has_shielded and has_unshielded and (operation_flags != 0b111)

            # ä¸ºæ¯ä¸ªæ¨¡å¼ç”Ÿæˆæ›¿æ¢é€‰é¡¹
            for pattern in patterns:
                candidates = replacements.get(pattern, [])
                # æ ¹æ®å¤„ç†æ¨¡å¼è¿‡æ»¤å€™é€‰è¯
                filtered = [
                    repl for repl in candidates
                    if not filter_special or ("â—" not in repl and "â—‹" not in repl)
                ]
                
                # æ·»åŠ åŸè¯é€‰é¡¹çš„æ¡ä»¶å¤„ç†ï¼ˆéå…¨å¤„ç†æ¨¡å¼ä¸”å½“å‰æ¨¡å¼æ— å±è”½ç¬¦å·ï¼‰
                if need_extra and ("â—" not in pattern and "â—‹" not in pattern):
                    if pattern not in filtered:
                        filtered.append(pattern)
                
                replacement_options[pattern] = filtered

            # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ›¿æ¢ç»„åˆï¼ˆç¬›å¡å°”ç§¯ï¼‰
            results = set()
            for combo in product(*[replacement_options[p] for p in patterns]):
                temp_str = string  # ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²ä»¥ä¿ç•™â—‹ç¬¦å·
                replace_actions = []
                
                # æ”¶é›†æ‰€æœ‰æ›¿æ¢æ“ä½œ
                for pattern_idx, chosen_repl in enumerate(combo):
                    current_pattern = patterns[pattern_idx]
                    for m in pattern_groups[current_pattern]:
                        # è®°å½•æ›¿æ¢ä½ç½®å’Œå†…å®¹
                        replace_actions.append( (m.start(), m.end(), chosen_repl) )
                
                # æŒ‰å€’åºæ‰§è¡Œæ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
                replace_actions.sort(reverse=True, key=lambda x: x[0])
                for start, end, repl in replace_actions:
                    temp_str = temp_str[:start] + repl + temp_str[end:]
                
                results.add(temp_str)

            # ç»“æœæ’åºï¼šæœªå±è”½ç‰ˆæœ¬ä¼˜å…ˆ
            results = sorted(
                list(results),
                key=lambda s: any(c in s for c in ('â—', 'â—‹'))  # åŒ…å«å±è”½ç¬¦å·çš„æ’åœ¨åé¢
            )
        else:
            results = [string]  # æ— åŒ¹é…æ—¶è¿”å›åŸå§‹å­—ç¬¦ä¸²

    # ========================
    # é˜¶æ®µ2ï¼šå…¨è§’è½¬åŠè§’å¤„ç†
    # ========================
    conver_list = list(results)
    if operation_flags & 0b010:
        for i in range(len(conver_list)):
            s = conver_list[i]
            for full, half in config.full_half_char:
                s = s.replace(full, half)
            conver_list[i] = s

    # ========================
    # é˜¶æ®µ3ï¼šæ ¼å¼æ¸…ç†å’Œå¤§å†™è½¬æ¢
    # ========================
    if operation_flags & 0b100:
        conver_list = [
            # ç§»é™¤éå•è¯å­—ç¬¦ï¼ˆä¿ç•™å­—æ¯ã€æ•°å­—ã€æ±‰å­—ï¼‰å¹¶è½¬ä¸ºå¤§å†™
            re.sub(r"[\W_]+", "", s).upper()
            for s in conver_list
        ]

    # ========================
    # æœ€ç»ˆå¤„ç†ï¼šå»é‡å¹¶ä¿æŒé¡ºåº
    # ========================
    seen = set()
    final_results = []
    for s in conver_list:
        if s and (s not in seen):  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å¹¶å»é‡
            seen.add(s)
            final_results.append(s)
    
    return final_results


def get_new_release(release):
    release_rule = config.release_rule
    if not release:
        release = "0000-00-00"
    if release_rule == "YYYY-MM-DD":
        return release
    year, month, day = re.findall(r"(\d{4})-(\d{2})-(\d{2})", release)[0]
    return release_rule.replace("YYYY", year).replace("YY", year[-2:]).replace("MM", month).replace("DD", day)


def nfd2c(path):
    # è½¬æ¢ NFC(mac nfcå’Œnfdéƒ½èƒ½è®¿é—®åˆ°æ–‡ä»¶ï¼Œä½†æ˜¯æ˜¾ç¤ºçš„æ˜¯nfdï¼Œè¿™é‡Œç»Ÿä¸€ä½¿ç”¨nfcï¼Œé¿å…å„ç§é—®é¢˜ã€‚
    # æ—¥æ–‡æµŠéŸ³è½¬æ¢ï¼ˆmacçš„å‘ï¼Œosx10.12ä»¥ä¸‹ä½¿ç”¨nfdï¼Œä»¥ä¸Šå…¼å®¹nfcå’Œnfdï¼Œåªæ˜¯æ˜¾ç¤ºæˆäº†nfdï¼‰
    if config.is_nfc:
        new_path = unicodedata.normalize("NFC", path)  # Mac ä¼šæ‹†æˆä¸¤ä¸ªå­—ç¬¦ï¼Œå³ NFDï¼Œwindwosæ˜¯ NFC
    else:
        new_path = unicodedata.normalize("NFD", path)  # Mac ä¼šæ‹†æˆä¸¤ä¸ªå­—ç¬¦ï¼Œå³ NFDï¼Œwindwosæ˜¯ NFC
    return new_path


def deal_some_field(json_data):
    fields_rule = config.fields_rule
    actor = json_data["actor"]
    title = json_data["title"]
    originaltitle = json_data["originaltitle"]
    number = json_data["number"]

    # æ¼”å‘˜å¤„ç†
    if actor:
        # å»é™¤æ¼”å‘˜åä¸­çš„æ‹¬å·
        new_actor_list = []
        actor_list = []
        temp_actor_list = []
        for each_actor in actor.split(","):
            if each_actor and each_actor not in actor_list:
                actor_list.append(each_actor)
                new_actor = re.findall(r"[^\(\)\ï¼ˆ\ï¼‰]+", each_actor)
                if new_actor[0] not in new_actor_list:
                    new_actor_list.append(new_actor[0])
                temp_actor_list.extend(new_actor)
        if "del_char" in fields_rule:
            json_data["actor"] = ",".join(new_actor_list)
        else:
            json_data["actor"] = ",".join(actor_list)

        # å»é™¤æ ‡é¢˜åçš„æ¼”å‘˜å
        if "del_actor" in fields_rule:
            new_all_actor_name_list = []
            for each_actor in json_data["actor_amazon"] + temp_actor_list:
                actor_keyword_list = resources.get_actor_data(each_actor).get(
                    "keyword"
                )  # è·å–æ¼”å‘˜æ˜ å°„è¡¨çš„æ‰€æœ‰æ¼”å‘˜åˆ«åè¿›è¡Œæ›¿æ¢
                new_all_actor_name_list.extend(actor_keyword_list)
            for each_actor in set(new_all_actor_name_list):
                try:
                    end_actor = re.compile(r" %s$" % each_actor)
                    title = re.sub(end_actor, "", title)
                    originaltitle = re.sub(end_actor, "", originaltitle)
                except:
                    signal.show_traceback_log(traceback.format_exc())
        json_data["title"] = title.strip()
        json_data["originaltitle"] = originaltitle.strip()

    # å»é™¤æ ‡é¢˜ä¸­çš„ç•ªå·
    if number != title and title.startswith(number):
        title = title.replace(number, "").strip()
        json_data["title"] = title
    if number != originaltitle and originaltitle.startswith(number):
        originaltitle = originaltitle.replace(number, "").strip()
        json_data["originaltitle"] = originaltitle

    # å»é™¤æ ‡é¢˜ä¸­çš„/
    json_data["title"] = json_data["title"].replace("/", "#").strip(" -")
    json_data["originaltitle"] = json_data["originaltitle"].replace("/", "#").strip(" -")

    # å»é™¤ç´ äººç•ªå·å‰ç¼€æ•°å­—
    if "del_num" in fields_rule:
        temp_n = re.findall(r"\d{3,}([a-zA-Z]+-\d+)", number)
        if temp_n:
            json_data["number"] = temp_n[0]
            json_data["letters"] = get_number_letters(json_data["number"])

    if number.endswith("Z"):
        json_data["number"] = json_data["number"][:-1] + "z"
    return json_data


def get_movie_path_setting(file_path=""):
    # å…ˆæŠŠ'\'è½¬æˆ'/'ä»¥ä¾¿åˆ¤æ–­æ˜¯è·¯å¾„è¿˜æ˜¯ç›®å½•
    movie_path = config.media_path.replace("\\", "/")  # ç”¨æˆ·è®¾ç½®çš„æ‰«æåª’ä½“è·¯å¾„
    if movie_path == "":  # æœªè®¾ç½®ä¸ºç©ºæ—¶ï¼Œä½¿ç”¨ä¸»ç¨‹åºç›®å½•
        movie_path = get_main_path()
    movie_path = nfd2c(movie_path)
    end_folder_name = split_path(movie_path)[1]
    # ç”¨æˆ·è®¾ç½®çš„è½¯é“¾æ¥è¾“å‡ºç›®å½•
    softlink_path = config.softlink_path.replace("\\", "/").replace("end_folder_name", end_folder_name)
    # ç”¨æˆ·è®¾ç½®çš„æˆåŠŸè¾“å‡ºç›®å½•
    success_folder = config.success_output_folder.replace("\\", "/").replace("end_folder_name", end_folder_name)
    # ç”¨æˆ·è®¾ç½®çš„å¤±è´¥è¾“å‡ºç›®å½•
    failed_folder = config.failed_output_folder.replace("\\", "/").replace("end_folder_name", end_folder_name)
    # ç”¨æˆ·è®¾ç½®çš„æ’é™¤ç›®å½•
    escape_folder_list = (
        config.folders.replace("\\", "/").replace("end_folder_name", end_folder_name).replace("ï¼Œ", ",").split(",")
    )
    # ç”¨æˆ·è®¾ç½®çš„å‰§ç…§å‰¯æœ¬ç›®å½•
    extrafanart_folder = config.extrafanart_folder.replace("\\", "/")

    # è·å–è·¯å¾„
    softlink_path = convert_path(get_path(movie_path, softlink_path))
    success_folder = convert_path(get_path(movie_path, success_folder))
    failed_folder = convert_path(get_path(movie_path, failed_folder))
    softlink_path = nfd2c(softlink_path)
    success_folder = nfd2c(success_folder)
    failed_folder = nfd2c(failed_folder)
    extrafanart_folder = nfd2c(extrafanart_folder)

    # è·å–æ’é™¤ç›®å½•å®Œæ•´è·¯å¾„ï¼ˆå°¾å·´æ·»åŠ /ï¼‰
    escape_folder_new_list = []
    for es in escape_folder_list:  # æ’é™¤ç›®å½•å¯ä»¥å¤šä¸ªï¼Œä»¥ï¼Œ,åˆ†å‰²
        es = es.strip(" ")
        if es:
            es = get_path(movie_path, es).replace("\\", "/")
            if es[-1] != "/":  # è·¯å¾„å°¾éƒ¨æ·»åŠ â€œ/â€ï¼Œæ–¹ä¾¿åé¢move_listæŸ¥æ‰¾æ—¶åŒ¹é…è·¯å¾„
                es += "/"
            es = nfd2c(es)
            escape_folder_new_list.append(es)

    if file_path:
        temp_path = movie_path
        if config.scrape_softlink_path:
            temp_path = softlink_path
        if "first_folder_name" in success_folder or "first_folder_name" in failed_folder:
            first_folder_name = re.findall(r"^/?([^/]+)/", file_path[len(temp_path) :].replace("\\", "/"))
            first_folder_name = first_folder_name[0] if first_folder_name else ""
            success_folder = success_folder.replace("first_folder_name", first_folder_name)
            failed_folder = failed_folder.replace("first_folder_name", first_folder_name)

    return (
        convert_path(movie_path),
        success_folder,
        failed_folder,
        escape_folder_new_list,
        extrafanart_folder,
        softlink_path,
    )
